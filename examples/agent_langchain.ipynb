{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to build a tool-using agent with LangChain\n",
    "\n",
    "This notebook takes you through how to use LangChain to augment an OpenAI model with access to external tools. In particular, you'll be able to create LLM agents that use custom tools to answer user queries.\n",
    "\n",
    "\n",
    "## What is Langchain?\n",
    "[LangChain](https://python.langchain.com/en/latest/index.html) is a framework for developing applications powered by language models. Their framework enables you to build layered LLM-powered applications that are context-aware and able to interact dynamically with their environment as agents, leading to simplified code for you and a more dynamic user experience for your customers.\n",
    "\n",
    "## Why do LLMs need to use Tools?\n",
    "One of the most common challenges with LLMs is overcoming the lack of recency and specificity in their training data - answers can be out of date, and they are prone to hallucinations given the huge variety in their knowledge base. Tools are a great method of allowing an LLM to answer within a controlled context that draws on your existing knowledge bases and internal APIs - instead of trying to prompt engineer the LLM all the way to your intended answer, you allow it access to tools that it calls on dynamically for info, parses, and serves to customer.\n",
    "\n",
    "Providing LLMs access to tools can enable them to answer questions with context directly from search engines, APIs or your own databases. Instead of answering directly, an LLM with access to tools can perform intermediate steps to gather relevant information. Tools can also be used in combination. [For example](https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl_chat.html), a language model can be made to use a search tool to lookup quantitative information and a calculator to execute calculations.\n",
    "\n",
    "## Notebook Sections\n",
    "\n",
    "- **Setup:** Import packages and connect to a Pinecone vector database.\n",
    "- **LLM Agent:** Build an agent that leverages a modified version of the [ReAct](https://react-lm.github.io/) framework to do chain-of-thought reasoning.\n",
    "- **LLM Agent with History:** Provide the LLM with access to previous steps in the conversation.\n",
    "- **Knowledge Base:** Create a knowledge base of \"Stuff You Should Know\" podcast episodes, to be accessed through a tool.\n",
    "- **LLM Agent with Tools:** Extend the agent with access to multiple tools and test that it uses them to answer questions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Import libraries and set up a connection to a [Pinecone](https://www.pinecone.io) vector database.\n",
    "\n",
    "You can substitute Pinecone for any other vectorstore or database - there are a [selection](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html) that are supported by Langchain natively, while other connectors will need to be developed yourself."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:16.281759100Z",
     "start_time": "2023-09-17T05:40:15.967869400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "import datetime\n",
    "from pprint import pprint, pp\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from helper import fg, bg, control\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Union\n",
    "import zipfile\n",
    "#from pydantic_v1 import BaseModel, Extra, Field, root_validator\n",
    "from bs4 import BeautifulSoup\n",
    "# Langchain imports\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser, AgentType, initialize_agent\n",
    "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
    "# LLM wrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "# Conversational memory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "# Embeddings and vectorstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Vectorstore Index\n",
    "index_name = 'dfv'\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "env = 'gcp-starter'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:16.281992500Z",
     "start_time": "2023-09-17T05:40:16.116148Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c85f298",
   "metadata": {},
   "source": [
    "For acquiring an API key to connect with Pinecone, you can set up a [free account](https://app.pinecone.io/) and store it in the `api_key` variable below or in your environment variables under `PINECONE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "['dfv']"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pinecone.init(api_key='4ea18324-3aee-437b-b09b-0e72026cae8b', environment=env)\n",
    "pinecone.whoami()\n",
    "\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "# if index_name in pinecone.list_indexes():\n",
    "#     pinecone.delete_index(index_name)\n",
    "\n",
    "# Creates new index\n",
    "try:\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        pinecone.create_index(name=index_name, dimension=1536)\n",
    "        print('created: ', index_name)\n",
    "    index = pinecone.Index(index_name=index_name)\n",
    "except Exception as e:\n",
    "    print(f'pinecone: {e}')\n",
    "\n",
    "# Confirm our index was created\n",
    "pinecone.list_indexes()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.131798600Z",
     "start_time": "2023-09-17T05:40:16.248452400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7e7644cd",
   "metadata": {},
   "source": [
    "Run this code block if you want to clear the index, or if the index doesn't exist yet\n",
    "\n",
    "```\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "\n",
    "# Creates new index\n",
    "pinecone.create_index(name=index_name, dimension=1536)\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Confirm our index was created\n",
    "pinecone.list_indexes()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb63e37",
   "metadata": {},
   "source": [
    "## LLM Agent\n",
    "\n",
    "An [LLM agent](https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html) in Langchain has many configurable components, which are detailed in the Langchain documentation.\n",
    "\n",
    "We'll employ a few of the core concepts to make an agent that talks in the way we want, can use tools to answer questions, and uses the appropriate language model to power the conversation.\n",
    "- **Prompt Template:** The input template to control the LLM's behaviour and how it accepts inputs and produces outputs - this is the brain that drives your application ([docs](https://python.langchain.com/en/latest/modules/prompts/prompt_templates.html)).\n",
    "- **Output Parser:** A method of parsing the output from the prompt. If the LLM produces output using certain headers, you can enable complex interactions where variables are generated by the LLM in their response and passed into the next step of the chain ([docs](https://python.langchain.com/en/latest/modules/prompts/output_parsers.html)).\n",
    "- **LLM Chain:** A Chain brings together a prompt template with an LLM that will execute it - in this case we'll be using ```gpt-3.5-turbo``` but this framework can be used with OpenAI completions models, or other LLMs entirely ([docs](https://python.langchain.com/en/latest/modules/chains.html)).\n",
    "- **Tool:** An external service that the LLM can use to retrieve information or execute commands should the user require it ([docs](https://python.langchain.com/en/latest/modules/agents/tools.html)).\n",
    "- **Agent:** The glue that brings all of this together, an agent can call multiple LLM Chains, each with their own tools. Agents can be extended with your own logic to allow retries, error handling and any other methods you choose to add reliability to your application ([docs](https://python.langchain.com/en/latest/modules/agents.html)).\n",
    "\n",
    "**NB:** Before using this cookbook with the Search tool you'll need to sign up on https://serpapi.com/ and generate an API key. Once you have it, store it in an environment variable named ```SERPAPI_API_KEY```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='connect_api', description='connect_api(host: str, port: int, parameters: dict = None) -> str - connect to specified host and port', args_schema=<class 'pydantic.main.connect_apiSchemaSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<function connect_api at 0x00000259FFCED9D0>, coroutine=None), Tool(name='fetch', description='get remote document', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=True, func=StructuredTool(name='fetch', description='fetch(url: str) -> str - fetch url', args_schema=<class 'pydantic.main.fetchSchemaSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<function fetch_url at 0x00000259FFE72040>, coroutine=None), coroutine=None), Tool(name='connect', description='network connect with the host port', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=True, func=StructuredTool(name='connect', description='connect(host: str, port: int) -> str - Searches the API for the query.', args_schema=<class 'pydantic.main.connectSchemaSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<function connect_api at 0x00000259FFE44E50>, coroutine=None), coroutine=None), Tool(name='Abstract Answer', description='useful for when you need to ask with search', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='5b9947f0f0d1189ca7f8e9569f98e770e5e60c80b42296d70910e1ef9d734cf1', aiosession=None)>, coroutine=None)]\n"
     ]
    }
   ],
   "source": [
    "# Initiate a Search tool - note you'll need to have set SERPAPI_API_KEY as an environment variable as per the above instructions\n",
    "# search = SerpAPIWrapper()\n",
    "#\n",
    "# class FunctionTool(BaseModel):\n",
    "#     def run(self, query: str) -> str:\n",
    "#         print(f'FunctionTool Item: {query}')\n",
    "#         return f\"answer: {bytes(m).hex().capitalize()}\"\n",
    "#\n",
    "import requests\n",
    "from langchain.tools import tool\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "\n",
    "def connect_api(host: str, port: int, parameters: dict = None) -> str:\n",
    "    url = f'http://{host}'\n",
    "    result = requests.post(url=url, port=port)\n",
    "    return f\"{result.text}\"\n",
    "\n",
    "\n",
    "connect_tool = StructuredTool.from_function(connect_api,\n",
    "                                            description='connect to specified host and port')\n",
    "\n",
    "\n",
    "@tool('connect', return_direct=False)\n",
    "def connect_api(host: str, port: int) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    print(f'{connect_api: {host}:{port}}')\n",
    "    results = f'Host: {host}\\r\\n\\r\\n'\n",
    "    return f\"reply at {host}:{port}: {results}\"\n",
    "\n",
    "\n",
    "@tool('fetch')\n",
    "def fetch_url(url: str) -> str:\n",
    "    \"\"\"fetch url\"\"\"\n",
    "    print(f'fetching {url}')\n",
    "    #result = requests.post(url)\n",
    "    #\n",
    "    # soup = BeautifulSoup(result.text, 'lxml')\n",
    "    # ps = [e.get_text() for e in soup.find_all('p')]\n",
    "    # article = '\\n'.join(ps)\n",
    "\n",
    "    loader = RecursiveUrlLoader(url, max_depth=2, timeout=3)\n",
    "    docs = loader.load()\n",
    "    print(docs)\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    print(docs_transformed)\n",
    "    if docs_transformed:\n",
    "        tr = docs_transformed[0].page_content()\n",
    "        print(f'result:{tr}')\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    return f\"{article}\"\n",
    "\n",
    "\n",
    "tools = [connect_tool]\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=fetch_url,\n",
    "        name=\"fetch\",\n",
    "        description='get remote document',\n",
    "        handle_tool_error=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define a list of tools\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=connect_api,\n",
    "        name=\"connect\",\n",
    "        description='network connect with the host port',\n",
    "        handle_tool_error=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "tools.append(\n",
    "    Tool(\n",
    "        name=\"Abstract Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.248455800Z",
     "start_time": "2023-09-17T05:40:17.131798600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "effae642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.397186400Z",
     "start_time": "2023-09-17T05:40:17.248455800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the prompt with input variables for tools, user input and a scratchpad for the model to record its workings\n",
    "template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do and where to get output\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "\n",
    "            thoughts += f\"\\nObservation: {observation[:4096]}\\nThought: \"\n",
    "\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        print(control.bold + f'formatted templtate:\\n---\\n{formatted}\\n---\\n', control.reset)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.498395400Z",
     "start_time": "2023-09-17T05:40:17.365876300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "533657a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.615153500Z",
     "start_time": "2023-09-17T05:40:17.498395400Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "\n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c7d93d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.715192200Z",
     "start_time": "2023-09-17T05:40:17.615153500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate our LLM - default is 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Using tools, the LLM chain and output_parser to make an agent\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    # We use \"Observation\" as our stop sequence so it will stop when it receives Tool output\n",
    "    # If you change your prompt template you'll need to adjust this as well\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# Initiate the agent that will respond to our queries\n",
    "# Set verbose=True to share the CoT reasoning the LLM goes through\n",
    "# print(tools)\n",
    "# llm = OpenAI(temperature=0)\n",
    "# agent_executor = initialize_agent(\n",
    "#     tool_names,\n",
    "#     llm=ll,\n",
    "#     agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=True)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:17.815689100Z",
     "start_time": "2023-09-17T05:40:17.715192200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7ca3ee2",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T05:40:20.565310100Z",
     "start_time": "2023-09-17T05:40:18.355547100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[01mformatted templtate:\n",
      "---\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "connect_api: connect_api(host: str, port: int, parameters: dict = None) -> str - connect to specified host and port\n",
      "fetch: get remote document\n",
      "connect: network connect with the host port\n",
      "Abstract Answer: useful for when you need to ask with search\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do and where to get output\n",
      "Action: the action to take, should be one of [connect_api, fetch, connect, Abstract Answer]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what content can be on port 80 of google.com? \n",
      "\n",
      "---\n",
      " \u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: To determine what content can be on port 80 of google.com, we need to connect to the host and port and retrieve the information.\n",
      "Action: connect_api\n",
      "Action Input: connect_api(\"google.com\", 80)\u001B[0m"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for connect_apiSchemaSchema\nport\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[100], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#agent_executor.run(\"How many people live in canada as of 2023?\")\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43magent_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhat content can be on port 80 of google.com? \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\chains\\base.py:475\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    474\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 475\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[0;32m    476\u001B[0m         _output_key\n\u001B[0;32m    477\u001B[0m     ]\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[0;32m    481\u001B[0m         _output_key\n\u001B[0;32m    482\u001B[0m     ]\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\chains\\base.py:282\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    281\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 282\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    283\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    284\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    285\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[0;32m    286\u001B[0m )\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\chains\\base.py:276\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[0;32m    270\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    271\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    272\u001B[0m     inputs,\n\u001B[0;32m    273\u001B[0m )\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    275\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 276\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    278\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    279\u001B[0m     )\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    281\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1036\u001B[0m, in \u001B[0;36mAgentExecutor._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;66;03m# We now enter the agent loop (until it returns something).\u001B[39;00m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_continue(iterations, time_elapsed):\n\u001B[1;32m-> 1036\u001B[0m     next_step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_take_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1037\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1038\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1039\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1040\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1041\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1042\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(next_step_output, AgentFinish):\n\u001B[0;32m   1044\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return(\n\u001B[0;32m   1045\u001B[0m             next_step_output, intermediate_steps, run_manager\u001B[38;5;241m=\u001B[39mrun_manager\n\u001B[0;32m   1046\u001B[0m         )\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:891\u001B[0m, in \u001B[0;36mAgentExecutor._take_next_step\u001B[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[0m\n\u001B[0;32m    889\u001B[0m         tool_run_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_prefix\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    890\u001B[0m     \u001B[38;5;66;03m# We then call the tool on the tool input to get an observation\u001B[39;00m\n\u001B[1;32m--> 891\u001B[0m     observation \u001B[38;5;241m=\u001B[39m tool\u001B[38;5;241m.\u001B[39mrun(\n\u001B[0;32m    892\u001B[0m         agent_action\u001B[38;5;241m.\u001B[39mtool_input,\n\u001B[0;32m    893\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    894\u001B[0m         color\u001B[38;5;241m=\u001B[39mcolor,\n\u001B[0;32m    895\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    896\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtool_run_kwargs,\n\u001B[0;32m    897\u001B[0m     )\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    899\u001B[0m     tool_run_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magent\u001B[38;5;241m.\u001B[39mtool_run_logging_kwargs()\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\tools\\base.py:316\u001B[0m, in \u001B[0;36mBaseTool.run\u001B[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    305\u001B[0m     tool_input: Union[\u001B[38;5;28mstr\u001B[39m, Dict],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    314\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    315\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Run the tool.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m     parsed_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtool_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;129;01mand\u001B[39;00m verbose \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    318\u001B[0m         verbose_ \u001B[38;5;241m=\u001B[39m verbose\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\langchain\\tools\\base.py:252\u001B[0m, in \u001B[0;36mBaseTool._parse_input\u001B[1;34m(self, tool_input)\u001B[0m\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    251\u001B[0m         key_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(input_args\u001B[38;5;241m.\u001B[39m__fields__\u001B[38;5;241m.\u001B[39mkeys()))\n\u001B[1;32m--> 252\u001B[0m         \u001B[43minput_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[43mkey_\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_input\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tool_input\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\pydantic\\main.py:711\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.validate\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mF:\\openai-cookbook\\venv\\lib\\site-packages\\pydantic\\main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValidationError\u001B[0m: 1 validation error for connect_apiSchemaSchema\nport\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "#agent_executor.run(\"How many people live in canada as of 2023?\")\n",
    "agent_executor.run(\"what content can be on port 80 of google.com? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent_executor.run('what is on https://ya.ru/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff96040",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many in 2022?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b51817",
   "metadata": {},
   "source": [
    "## LLM Agent with History\n",
    "\n",
    "Extend the LLM Agent with the ability to retain a [memory](https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html#adding-memory) and use it as context as it continues the conversation.\n",
    "\n",
    "We use a simple ```ConversationBufferWindowMemory``` for this example that keeps a rolling window of the last two conversation turns. LangChain has other [memory options](https://python.langchain.com/en/latest/modules/memory.html), with different tradeoffs suitable for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85737eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which can interpolate the history\n",
    "template_with_history = \"\"\"You are SearchGPT, a professional search engine who provides informative answers to users. Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to give detailed, informative answers\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # The history template includes \"history\" as an input variable so we can interpolate it into the prompt\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the memory with k=2 to keep the last two turns\n",
    "# Provide the memory to the agent\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f031bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"how about in mexico?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62356eed",
   "metadata": {},
   "source": [
    "## Knowledge base\n",
    "\n",
    "Create a custom vectorstore for the Agent to use as a tool to answer questions with. We'll store the results in [Pinecone](https://docs.pinecone.io/docs/quickstart), which is supported by LangChain ([Docs](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html), [API reference](https://python.langchain.com/en/latest/reference/modules/vectorstore.html)). For help getting started with Pinecone or other vector databases, we have a [cookbook](https://github.com/openai/openai-cookbook/blob/colin/examples/vector_databases/Using_vector_databases_for_embeddings_search.ipynb) to help you get started.\n",
    "\n",
    "You can check the LangChain documentation to see what other [vectorstores](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html) and [databases](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html) are available.\n",
    "\n",
    "For this example we'll use the transcripts of the Stuff You Should Know podcast, which was provided thanks to OSF DOI [10.17605/OSF.IO/VM9NT](https://doi.org/10.17605/OSF.IO/VM9NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f86008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "# Here is a URL to a zip archive containing the transcribed podcasts\n",
    "# Note that this data has already been split into chunks and embeddings from OpenAI's text-embedding-ada-002 embedding model are included\n",
    "content_url = 'https://cdn.openai.com/API/examples/data/sysk_podcast_transcripts_embedded.json.zip'\n",
    "\n",
    "# Download the file (it is ~541 MB so this will take some time)\n",
    "wget.download(content_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load podcasts\n",
    "with zipfile.ZipFile(\"sysk_podcast_transcripts_embedded.json.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./data\")\n",
    "f = open('./data/sysk_podcast_transcripts_embedded.json')\n",
    "processed_podcasts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the contents\n",
    "pd.DataFrame(processed_podcasts).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9715d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the text embeddings to Pinecone\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(processed_podcasts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(processed_podcasts), i + batch_size)\n",
    "    meta_batch = processed_podcasts[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['cleaned_id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text_chunk'] for x in meta_batch]\n",
    "    # add embeddings\n",
    "    embeds = [x['embedding'] for x in meta_batch]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'filename':   x['filename'],\n",
    "        'title':      x['title'],\n",
    "        'text_chunk': x['text_chunk'],\n",
    "        'url':        x['url']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the embeddings to be used by our retriever to be OpenAI Embeddings, matching our embedded corpus\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Loads a docsearch object from an existing Pinecone index so we can retrieve from it\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings, text_key='text_chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd21d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_docs = retriever.get_relevant_documents(\"can you live without a bank account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016bd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the title and content for the most relevant retrieved documents\n",
    "print(\"\\n\".join(['Title: ' + x.metadata['title'].strip() + '\\n\\n' + x.page_content + '\\n\\n' for x in query_docs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf10f53",
   "metadata": {},
   "source": [
    "## LLM Agent with Tools\n",
    "\n",
    "Extend our list of tools by creating a [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html) chain leveraging our Pinecone knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cae4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retrieval_llm = OpenAI(temperature=0)\n",
    "\n",
    "podcast_retriever = RetrievalQA.from_chain_type(llm=retrieval_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=podcast_retriever.run,\n",
    "        description=\"Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e12121",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Re-initialize the agent with our new list of tools\n",
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=expanded_tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "multi_tool_names = [tool.name for tool in expanded_tools]\n",
    "multi_tool_agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=multi_tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tool_memory = ConversationBufferWindowMemory(k=2)\n",
    "multi_tool_executor = AgentExecutor.from_agent_and_tools(agent=multi_tool_agent, tools=expanded_tools, verbose=True, memory=multi_tool_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bb1de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_tool_executor.run(\"Hi, I'd like to know how you can live without a bank account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba815cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tool_executor.run('Can you tell me some interesting facts about whether zoos are good or bad for animals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe408a3",
   "metadata": {},
   "source": [
    "You now have a template to deploy conversational agents with tools. If you want to extend this with a Custom Agent to add your own retry behaviour or treatment of input/output variables, then follow [this article](https://python.langchain.com/en/latest/modules/agents/agents/custom_agent.html).\n",
    "\n",
    "We look forward to seeing what you build!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
